#+TITLE: Notes from Learning DDD

* Preface

Stages
1. Strategic design, in which we understand the business problem and
   break the problem down into smaller, solvable, interconnected problems.
2. Tactical design, where we transform the discoveries of strategic
   design into software architecture and implementation.

The book is divided into 4 parts:
- strategic design
- tactical design
- DDD in practice
- DDD's relationships to other methodologies

* Introduction

Most software fails in some way. The author posits that the cause is
communication issues. DDD proposes to attack the root cause through a
framework for effective communication. DDD can be divided into
strategic and tactical:

- The strategic tools of DDD are used to analyze business domains and
  strategy, and to foster a shared understanding of the business
  between the different stakeholders.
  - handles the what and why of the software we are building
- The tactical tools allow us to write code in a way that reflects the
  business domain, address its goals, and speak the language of the
  business.
  - the how, how each component is implemented

* 1. Analyzing Business Domains

This chapter is about learning how companies work: why they exist,
what goals they are pursuing, and their strategies for achieving their
goals. To design and build an effective solution, we have to
understand the problem.

To achieve its business domain's goals and targets, a company has to
operate in multiple subdomains. A *subdomain* is a fine-grained area of
business activity. A single subdomain is not enough for a company to
succeed, there has to be multiple subdomains that interact with each
other to achieve the company's goals in its business domain.

Ask whether the subdomain in question can be turned into a side
business. Would someone pay for it on it's own? If so, this is a core
subdomain.

| Subdomain type | Competitive advantage | Complexity | Volatility | Implementation      | Problem    |
|----------------+-----------------------+------------+------------+---------------------+------------|
| Core           | Yes                   | High       | High       | In-house            | Interesting|
| Generic        | No                    | High       | Low        | Buy/adopt           | Solved     |
| Supporting     | No                    | Low        | Low        | In-house/outsource  | Obvious    |


idea: Conway's law
What would software that runs the entirety of $EMPLOYER look like?

* 2. Discovering Domain Knowledge

Gherkin tests are good ways to make domain oriented scenarios that
define software behavior well

#+begin_text
Feature: Guess the word

  # The first example has two steps
  Scenario: Maker starts a game
    When the Maker starts a game
    Then the Maker waits for a Breaker to join

  # The second example has three steps
  Scenario: Breaker joins a game
    Given the Maker has started a game with the word "silky"
    When the Breaker joins the Maker's game
    Then the Breaker must guess a word with 5 characters
#+end_text

* 3. Managing Domain Complexity

Architectural design is system design. System design is contextual
design -- it is inherently about boundaries (what's in, what's out,
what moves between), and about trade-offs. It reshapes what is
outside, just as it shapes what is inside.

The bounded context pattern is the DDD tool for defining physical and
ownership boundaries.

Bounded contexts decompose a system into physical components—services,
subsystems, and so on. Each bounded context’s lifecycle is decoupled
from the rest. Each bounded context can evolve independently from the
rest of the system. However, the bounded contexts have to work
together to form a system. Some of the changes will inadvertently
affect another bounded context. In the next chapter, we’ll talk about
the different patterns for integrating bounded contexts that can be
used to protect them from cascading changes.

* 4. Integrating Bounded Contexts

Although bounded contexts can evolve independently, they have to
integrate with one another. As a result, there will always be
touchpoints between bounded contexts. These are called /contracts/.

This chapter focuses on defining relationshiops and integrations
between bounded contexts. The book divides these into 3 groups, each
representing a type of team collaboration: cooperation,
customer-supplier, and separate ways.

** Cooperation

Bounded contexts implemented by teams with well-established
communication. This applies to single teams, or teams with dependent
goals. The main criteria is the quality of the teams' communications
and collaboration.

2 DDD patterns suitable for cooperating teams:

*** Partnership

Integration between bounded contexts is coordinated in an ad hoc
manner. One team can notify a second team about a change in the API,
and the second team will cooperate and adapt -- no drama or conflicts.

*** Shared Kernel

A case where the same model of a subdomain, or a part of it, will be
implemented in multiple bounded contexts. The shared model is designed
according to the needs of all it's overlapping bounded contexts, and
each change has to be consistent across each bounded context.

The overarching applicability criterion for the shared kernel pattern
is the cost of duplication vs the cost of coordination.

** Customer-Supplier

The supplier provides a service for its customers. Unlike in
cooperation, both teams can succeed independently. In most cases, we
have an imbalance of power: either the upstream or downstream team can
dictate the integration contract.

3 patterns addressing such power differences:

*** Conformist

balance of power favors the upstream team, which has no real
motivation to support its clients' needs. The supplier offers a
contract according to its own model, and if the downstream team can
accept it the relationship is called conformist.

*** Anticorruption Layer

The consumer is not willing to accept the supplier's model. Instead,
the downstream (customer) translates the supplier's bounded context's
model into a model tailored to its own needs via an anticorruption
layer.

Some reasons this may happen:

- downstream bounded context contains a core subdomain
- upstream model is iniefficient or inconvenient for the customer's needs
- the upstream contract changes often

*** Open-host Service

The case in which the power is skewed toward the consumers. The
supplier is interested in protecting its consumers and providing the
best service possible. To protect consumers from its implementation
model, the upstream supplier decouples the implementation model from
the public interface.

In a sense, this pattern is the opposite of the anticorruption layer
pattern. Instead of the consumer, the supplier implements the
translation of its internal model.

** Separate ways

The last collaboration option is not to collaborate at all.

* 5. Implementing Simple Business Logic

We start with 2 patterns suited for simple business logic: transaction
script and active record.

** Transaction Script

Organizes business logic by procedures where each procedure handles a
single request from the presentation - Martin Fowler

A system's public interface can be seen as a collection of business
transactions that consumers can execute. The pattern organizes the
system's business logic based on procedures, where each procedure
implements an operation that is executed by the system's consumer via
its public interface. In effect, the system's public operations are
used an encapsulation boundaries.

*** Implementation

Each procedure is a straightforward procedural script. The only
requirement procedures have to fulfill is transactional behavior. Each
operation should either succeed or fail, but can never result in an
invalid state.

This is kind of like the unit of work implementation.

** Active Record

An object that wraps a row in a database table or view, encapsulates
the database access, and adds domain logic on that data. - Martin
Fowler

*** Implementation

This pattern uses objects, known as active records, to represent
complicated data structures. It also implements data access methodsw
for CRUD operations. The active record objects are coupled to an ORM
or some other data access framework. The pattern's name is derived
from the fact that each data structure is 'active', i.e. it implements
data access logic.

An active record is essentially a transaction script that optimizes
access to databases.

BUILD: Active Record Implementation
BUILD: Transaction Script Implementation

* 6. Tackling Complex Business Logic

This chapter introduces a pattern oriented for complicated business
logic: the domain model pattern. The pattern is "domain model", and
the aggregates and value objects are its building blocks.

** Domain Model

Instead of CRUD interfaces, we deal with complicated state
transitions, business rules, and invariants: rules that have to be
protected at all times.

*** Implementation

A domain model is an object model of the domain that incorporates both
behavior and data. DDD's tactical patterns -- aggregates, value
objects, domain events, and domain services -- are the building blocks
of such an object model. These all share a common theme: they put the
business logic first.

The model should be devoid of any infrastructural or technological
concerns, such as implementing calls to databases or other external
components of the system.

*** Building Blocks

**** Value object

A value object is an object that can be identified by the composition
of its values. The composition of the fields should be unique.

***** Ubiquitous Language

Relying exclusively on the language's standard library's primitive
data types (strs, ints, dicts, etc) to represent concepts of the
business domain is known as the primitive obsession code smell.

The author suggests that you build a bunch of specific, well-named
data types for inputting values. The validation logic can lie in the
value objects themselves. Most importantly, value objects express the
business domain's concepts: they make the code speak the ubiquitous
language.

**** Entities

An entity is the opposite of a value object. It requires an explicit
identification field to distinguish between the different instances of
the entity.

Contrary to value objects, entities are mutable and expected to
change. Entities are an essential building block of any business
domain.

***** Aggregates

An aggregate is an /entity/: it requires an explicit identification
field and its state is expected to change during an instance's
lifecycle. The goal of the pattern is to protect the consistency of
its data. Since an aggregate's data is mutable, there are implications
and challenges that the pattern has to address to keep its state
consistent at all times.

****** Consistency Enforcement

The aggregate is a consistency enforcement boundary. The aggregate's
logic has to validate all incoming modifications and ensure that
changes do not contradict its business rules. In the implementation,
the consistency is enforced by allowing only the aggregate's business
logic to modify its state. All processes or objects external to the
aggregate are only allowed to read the object's state. Its state can
only be mutated by executing corresponding methods of the aggregate's
public interface.

The state-modifying methods exposed as an aggregate's public interface
are often referred to as commands (as in a "command to do something").

****** Transaction Boundary

Since an aggregate's state can only be modified by its own business
logic, the aggregate also acts as a transactional boundary. All
changes to the aggregate's state should be committed transactionally
as one atomic operation.

Furthermore, no system operation can assume a multi-aggregate
transaction. A change to the aggregate's state can only be committed
individually, one aggregate per database transaction.

****** Hierarchy of Entities

We don't use entites as an independent pattern, only as part of an
aggregate.

BUILD: An example hierarchy of entities / aggregate with a well defined
transactional boundary and aggregate root.

This pattern is named "aggregate" because it aggregates business
entities and value objects that belong to the same transaction
boundary.


#+DOWNLOADED: screenshot @ 2024-04-21 11:57:34
[[file:6._Tackling_Complex_Business_Logic/2024-04-21_11-57-34_screenshot.png]]

****** Domain Events

A domain event is a message describing a significant event that has
occurred in the business domain. The goal of a domain event is to
describe what has happened in the business domain and provide all the
necessary data related to the event.

****** Domain Services

Eventually we encounter business logic that doesn't belong to any
aggregate or value object, or that seems relevant to multiple
aggregates. In such cases, DDD proposes to implement the logic as a
domain service.

A /domain service/ is a stateless object that implements the business
logic. Most of the time, the logic orchestrates calls to various
components of the system to perform some calculation or
analysis. Domain services lend themselves to implementing calculation
logic that requires reading the data of multiple aggregates.

This is not a microservice, SOA, or anything similar -- just a
stateless object used to host business logic.

** Managing Complexity

Eliyahu M. Goldratt says wehn discussing the complexity of a system,
we are interested in evaluating the difficulty of controlling and
predicting the system's behavior. These are reflected by the system's
degrees of freedom. A system's degrees of freedom are the data points
needed to describe its state.

A good rule of thumb is to limit the number of data points something
needs to take to perform its duty.

** Conclusion

The domain model handles complex business logic, and consists of 3
main building blocks:

- Value objects
  - concepts of the domain that can be identified exclusively by their
    values and thus do not require an explicit id field
- Aggregates
  - A hierarchy of entities sharing a transactional boundary. All of
    the data included in an aggregate's boundary has to be strongly
    consistent to implement its business logic.
- Domain Services
  - A stateless object that hosts business logic that doesn't
    naturally belong to the domain model's aggregates or value objects


Value objects describe entities' properties, and entities are bound
together into aggregates.

BUILD: Basic program that uses all 3 (value objects, aggregates,
domain services)

* 7. Modeling the Dimension of Time

The event-sourced domain model pattern is based on the same premise as
the domain model pattern, but the way the aggregates' state is
persisted is different. The event-sourced model uses the event
sourcing pattern to manage the aggregate's states: instead of
persisting an aggregate's state, the model generates domain events
describing each change and uses them as the source of truth for the
aggregate's data.

** Event Sourcing

The event sourcing pattern introduces the dimension of time into the
data model.

here is an example of a data representation in an event-sourced
system:


#+DOWNLOADED: screenshot @ 2024-04-21 12:34:01
[[file:7._Modeling_the_Dimension_of_Time/2024-04-21_12-34-01_screenshot.png]]

** Source of Truth

For the event sourcing pattern to work, all changes to an object's
state should be represented and persisted as events.

*** Event Store

The event store should be an append-only storage. This is essentially
a ledger.

BUILD: An event sourcing system with an event store

** Event-Sourced Domain Model

The original domain model maintains a state representation of its
aggregates and emtis select domain events. The *event-sourced* domain
model uses domain events exclusively for modeling the aggregates'
lifecycles.

Each operation on an event-sourced aggregate follows this script:

- load the aggregate's domain events
- reconstitute a state representation - project the events into a
  state representation that can be used to make business decisions
- execute the aggregate's command to execute the business logic, and
  consequently, produce new domain events
- commit the new domain events to the event store

** Advantages
- time traveling
- deep insight
- audit log
- advanced optimistic concurrency management

** Disadvantages
- learning curve
- evolving the model
- architectural complexity

* 8. Architectural Patterns

This chapter focuses on tactical design decisions in a broader
context: the different ways to orchestrate the interactions and
dependencies between a system's components.

Architectural patterns introduce organizational principles for the
different aspects of a codebase and present clear boundaries between
them: how the business logic is wired to the systems' input, output,
and other infrastructural components.

** Layered architecture


#+DOWNLOADED: screenshot @ 2024-04-21 13:02:43
[[file:8._Architectural_Patterns/2024-04-21_13-02-43_screenshot.png]]

*** Variation

It's common to see the layered architecture pattern also have a
service layer.

#+begin_quote
Defines an application's boundary with a layer of servies that
establishes a set of available operations and coordinates the
application's response in each operation.

- Patterns of Enterprise Application Architecture
#+end_quote


#+DOWNLOADED: screenshot @ 2024-04-21 13:04:30
[[file:8._Architectural_Patterns/2024-04-21_13-04-30_screenshot.png]]

Having an explicit service level has some advantages:

- we can reuse the same service layer to serve multiple public
  interfaces, e.g. a GUI and an API, without duplication of
  orchestration logic
- improved modularity
- further decouples the presentation and business logic layers
- makes it easier to test the business functionality

** Ports & Adapters

#+DOWNLOADED: screenshot @ 2024-04-21 13:09:03
[[file:8._Architectural_Patterns/2024-04-21_13-09-03_screenshot.png]]

The core goal of the ports & adapters architecture (also known as
hexagonal, onion, or clean architecture) is to decouple the system's
business logic from it's infrastructure components. Instead of
referencing and calling the infrastructural components directly, the
business logic layer defines "ports" that have to be implemented by
the infrastructure layer. The infrastructure layer implements
"adapters": concrete implementations of the ports interfaces for
working with different technologies.

** Command-Query Responsibility Segregation

This pattern enables representation of the system's data in multiple
persistent models.

We focus on how CQRS allows the use of multiple storage mechanisms for
representing different models of the system's data.

*** Implementation

There are 2 models (and this pattern separates them):
- the command execution model
  - executes operations that modify the system's state.
  - used to implement business logic, validate rules, and enforce
    invariants
- read models
  - as many models as needed to present data to users or supply
    information to other systems

*** Model Segregation

In the CQRS architecture, the responsibilities of the system's models
are segregated according to their type. A command can only operate on
the strongly consistent command execution model. A query cannot
directly modify any of the system's persisted state -- netierh the
read models nor the command execution model.

The command can -- and in many cases should -- return data.

*** When to use CQRS

The CQRS pattern can be useful for applications that need to work with
the same data in multiple models, potentially stored in different
kinds of databases.

* 9. Communication Patterns

This chapter discusses patterns for organizing the flow of
communication across a system's elements.

** Model Translation

In a customer-supplier relationship, the balance of power tips either
upstream (supplier) or downstream (consumer). Suppose the downstream
bounded context cannot conform to the upstream bounded context's
model. In this case, a more elaborate technical solution is required
that can facilitate communication by translating the bounded contexts'
models.

This translation can be handled by one, or sometimes both, sides using
an anticorruption layer or an open-host service. This chapter covers
the implementation options for model translation without
differentiating between the patterns.

The model's translation logic can be either stateless or stateful.

- stateless translation happens on the fly, as incoming or outgoing
  requests are issued
- stateful translation involves a more complicated translation logic.

*** Stateless Model Translation

For stateless model translation, the bounded context that owns the
translation implements the proxy design pattern to interject the
incoming and outgoing requests and map the source model to the bounded
context's model

#+begin_src python
class CustomerManagementService:
    """Simulate a remote service in the Customer Management bounded context."""
    def get_customer_details(self, customer_id):
        # Assume fetching customer details is a complex operation.
        print(f"Fetching details for customer {customer_id}")
        return {"customer_id": customer_id, "name": "John Doe", "credit_limit": 5000}

class CustomerProxy:
    """Proxy to interact with the Customer Management Service."""
    def __init__(self):
        self.customer_service = CustomerManagementService()
        self.cache = {}

    def get_customer_details(self, customer_id):
        if customer_id in self.cache:
            print("Returning cached data")
            return self.cache[customer_id]

        details = self.customer_service.get_customer_details(customer_id)
        # Cache the fetched details
        self.cache[customer_id] = details
        return details

class OrderService:
    """Order Processing context that uses a proxy to access customer data."""
    def __init__(self, customer_proxy):
        self.customer_proxy = customer_proxy

    def process_order(self, customer_id, order_amount):
        customer_details = self.customer_proxy.get_customer_details(customer_id)
        if order_amount <= customer_details["credit_limit"]:
            print(f"Order processed for {customer_details['name']} with amount ${order_amount}")
        else:
            print("Order amount exceeds credit limit. Cannot process order.")

# Example usage
customer_proxy = CustomerProxy()
order_service = OrderService(customer_proxy)

# Processing an order
order_service.process_order("C001", 1000)
order_service.process_order("C001", 300)  # This time, it should use cached data.
#+end_src

BUILD: anticorruption layer system

*** Stateful Model Translation

For more significant model transformations, for example when the
translation mechanism has to aggregate the source data or unify data
from multiple sources into a single model -- a stateful translation
may be required.

*Aggregating incoming data* often requires persistent storage. In some
 cases, we can use off the shell products.

*Unifying multiple sources*
In this case it can be beneficial to decouple the integration and
business logic complexities by fronting the bounded context with an
anticorruption layer that aggregates data from all other bounded
contexts.

** Integrating Aggregates
Earlier we discussed that one of the ways aggregates communicate with
the rest of the system is by publishing domain events. External
components can subscribe to these domain events and execute their
logic. This section focuses on how domain events are published to a
message bus.

*** Outbox

The outbox pattern ensures reliable publishing of domain events using
the following algorithm:

- Both the updated aggregate's state and the new domain events are
  committed in the same atomic transaction
- A message relay fetches newly committed domain events from the database
- The relay publishes the domain events to the message bus
- Upon successful publishing, the relay either marks the events as
  published in the database or deletes them completely


#+begin_src python
import sqlite3
import json

def process_order(order_id, new_status):
    db_connection = sqlite3.connect('application.db')
    cursor = db_connection.cursor()

    try:
        # Update the order status in the database
        cursor.execute('UPDATE orders SET status = ? WHERE order_id = ?', (new_status, order_id))

        # Prepare the message for the outbox
        message = {'order_id': order_id, 'new_status': new_status}
        cursor.execute('INSERT INTO outbox (message) VALUES (?)', (json.dumps(message),))

        # Commit the transaction (both operations are atomic)
        db_connection.commit()
        print("Order processed and message saved to outbox.")

    except Exception as e:
        db_connection.rollback()
        print("Failed to process order:", e)

    finally:
        db_connection.close()

def relay_messages():
    db_connection = sqlite3.connect('application.db')
    cursor = db_connection.cursor()
    cursor.execute('SELECT * FROM outbox')

    messages = cursor.fetchall()
    for message in messages:
        # Simulate sending the message to a message bus
        print("Publishing message:", message[1])
        cursor.execute('DELETE FROM outbox WHERE id = ?', (message[0],))

    db_connection.commit()
    db_connection.close()

# Assuming we have a table `orders` with columns `order_id`, `status`
# and a table `outbox` with columns `id`, `message`

# Process an order update
process_order(123, 'Shipped')
# Relay messages to the message bus
relay_messages()
#+end_src

** Saga

One of the core aggregate design principles is to limit each
transaction to a single instance of an aggregate. Sometimes there are
cases when you have to implement a business process that spans
multiple aggregates.

A saga is a long-running (in terms of transactions) business
process. The transactions can be handled by not only aggregates but
also by any component emitting domain events and responding to
commands. If one of the execution steps fails, the saga is in charge
of issuing relevant compensating actions to ensure the system state
remains consistent.

*** Consistency

Although the saga pattern orchestrates a multicomponent transaction,
the states of the involved components are eventually consistent.

#+begin_quote
Only the data within an aggregate's boundaries can be considered
strongly consistent. Everything outside is eventually consistent.
#+end_quote

Use this as a guiding principle to make sure you are not abusing sagas
to compensate for improper aggregate boundaries.

** Process Manager

The saga pattern manages a simple, linear flow that matches events to
the corresponding commands.

The process manager is intended to create a central processing unit
that maintains the state of the sequence and determines the next
processing steps.

As a simple rule of thumb, if a saga contains if-else statements to
choose the correct course of action, it is probably a process manager.

** Sagas
    Sagas are a sequence of local transactions that are distributed
    across multiple services or bounded contexts. Each transaction in
    a saga updates data within its own domain and can trigger
    subsequent transactions in other services through events.

*** Key Characteristics of Sagas
        - Decentralization: Sagas typically operate without a central
          coordinator.
        - Compensation: Sagas use compensatory actions to maintain
          consistency across services if any part of the process
          fails.
        - Event-Driven: Sagas rely on events to communicate between
          services, fostering asynchronous and loosely coupled
          interactions.

** Process Managers
    Process managers, sometimes called saga orchestrators, are
    designed to manage and coordinate complex business processes that
    span multiple services. Unlike sagas, process managers have a
    central role in directing the interactions between services.

*** Key Characteristics of Process Managers
        - Centralized Control: Process managers act as orchestrators,
          managing the state of the overall process and directing the
          flow based on outcomes.
        - Stateful: They maintain the state of the process, making
          decisions based on this accumulated state.
        - Command-Driven: Process managers use commands to direct
          services to perform specific operations, although they may
          also listen to events to determine outcomes.

** Differences Highlighted
    The main differences between sagas and process managers lie in
    their coordination style, communication mechanism, and how they
    manage state.

**** Coordination Style
        - Sagas: Decentralized, with each step autonomously triggering
          the next through events.
        - Process Managers: Centralized, explicitly managing and
          directing the business process.

**** Communication Mechanism
        - Sagas: Event-driven, promoting loose coupling between
          services.
        - Process Managers: Command-driven, providing explicit
          directives to services.

**** State Management
        - Sagas: Each service manages its own state; overall
          consistency is maintained through compensatory actions.
        - Process Managers: Maintain state for the entire business
          process, tracking progress and directing next steps.

** Example Scenario
    Consider an e-commerce system where the order processing involves
    multiple services such as order management, inventory, and
    billing.

**** As a Saga
        Each service independently reacts to events, starting with the
        Order Service creating an order and emitting an `OrderCreated`
        event, followed by the Inventory Service reacting to reserve
        items and emit further events based on the outcome.

**** As Managed by a Process Manager
        A Process Manager orchestrates the entire process, starting
        with a command to create an order, and based on the response,
        it directs subsequent actions to other services. It also
        explicitly manages compensating actions in case of failures.

* 10. Design Heuristics

** Bounded Contexts

Rather than making the model a function of the desired size --
optimizing for small bounded contexts -- it's much more effective to
do the opposite: treat the bounded context's size as a function of the
model it encompasses.

When designing bounded contexts, start with wider boundaries. If
required, decompose the wide boundaries into smaller ones as you gain
domain knowledge.

** Business Logic Implementation Patterns

In ch 5-7 we learned 4 ways tomodel business logic: transaction
script, active record, domain model, and event-sourced domain model
patterns.

The difference between active record and transaction script is the
complexity of the data structures. The other 2 (domain model,
event-sourced), lend themselves to subdomains that have complex
business logic: core subdomains.


#+DOWNLOADED: screenshot @ 2024-04-23 16:45:24
[[file:10._Design_Heuristics/2024-04-23_16-45-24_screenshot.png]]

** Architectural Patterns

In ch 8 we looked at a layered architecture, ports & adapters, and
CQRS.

#+DOWNLOADED: screenshot @ 2024-04-23 16:47:10
[[file:10._Design_Heuristics/2024-04-23_16-47-10_screenshot.png]]

** Testing Strategy


#+DOWNLOADED: screenshot @ 2024-04-23 16:48:47
[[file:10._Design_Heuristics/2024-04-23_16-48-47_screenshot.png]]

** Tactical Design Decision Tree


#+DOWNLOADED: screenshot @ 2024-04-23 16:49:39
[[file:10._Design_Heuristics/2024-04-23_16-49-39_screenshot.png]]

BUILD: Ports & Adapters Architecture
BUILD: CQRS implementation

* 11. Evolving Design Decisions

** Tactical Design Concerns

The main indicator of a change in a subdomain's type is the inability
of existing technical design to support current business needs.

*** Transaction Script -> Active Record

when working with data becomes challenging in a transaction script,
refactor it into the active record pattern.

*** Active Record -> Domain Model

If the business logic that manipulates active records becomes complex
and you notice more cases of inconsistencies, refactor the
implementation to the domain model pattern.

*** Domain Model to Event-Sourced Domain Model

Instead of modifying the aggregate's data directly, model the domain
events needed to represent the aggregate's lifecycle.

The most challening aspect of refactoring a domain model into an
event-sourced domain model is the history of the existing aggregates:
migrating the 'timeless' state into the event-based model.

* 12. Event Storming

Event-storming is a low-tech activity for a group of people to
brainstorm and rapidly model a business process.

An event storming session has a scope: the business process that the
group is interested in exploring.

Keep the group on the smaller side, ideally < 10 people.

** What do you need for Event Storming?

- Modeling Space
  - A whole wall covered with butcher paper makes the best space, but
    a large whiteboard can work.
- Sticky Notes
  - different colors. Each note represents different concepts of the
    business domain.
- Markers
  - for writing on the sticky notes
- Snacks
  - typically a session lasts 2-4 hours
- Room
  - of the spacious variety
  - if possible, remove the table and chairs. Force people to stand.

** The Event Storming Process

*** Unstructured exploration
   * A domain event is something interesting that
     has happened in the business. Formulate in past tense
   * All participants grab orange sticky notes, writing whatever domain
     events come to mind.

     #+DOWNLOADED: screenshot @ 2024-04-24 06:34:02
     [[file:12._Event_Storming/2024-04-24_06-34-02_screenshot.png]]


*** Timelines
   * Go over the generated domain events and organize them in the
     order in which they occur in the business domain.
   * Events should start with the happy path scenario
   * Following happy path, alternative scenarios can be added

     #+DOWNLOADED: screenshot @ 2024-04-24 06:34:18
     [[file:12._Event_Storming/2024-04-24_06-34-18_screenshot.png]]

*** Pain Points
   * Once we have a timeline, identify points in the process that
     require attention, i.e. bottlenecks, manual steps, missing docs,
     missing domain knowledge

     #+DOWNLOADED: screenshot @ 2024-04-24 06:35:20
     [[file:12._Event_Storming/2024-04-24_06-35-20_screenshot.png]]

*** Pivotal Events
   * Look for significant business events indicating a change in the
     context or phase.
   * Mark pivotal events with a vertical bar dividing the events
     before and after the pivotal event
   * e.g. shopping cart initialized, order initialized, order shipped,
     order delivered, order returned


#+DOWNLOADED: screenshot @ 2024-04-24 06:37:52
[[file:12._Event_Storming/2024-04-24_06-37-52_screenshot.png]]


*** Commands
   * Commands describe what triggered an event or flow of events
   * These describe the system's operations and are formulated in the
     imperative.
   * e.g. publish campaign, roll back transaction, submit order
   * light blue sticky notes
   * If a particular command is executed by an actor in a specific
     role, the actor information is added to the command on a small
     yellow sticky note. Add actors only when it's obvious.


#+DOWNLOADED: screenshot @ 2024-04-24 06:40:16
[[file:12._Event_Storming/2024-04-24_06-40-16_screenshot.png]]

*** Policies
   * Some commands are added to the model but have no specific actor
     associated with them.
   * Look for automation policies that might execute those commands
   * purple sticky notes


#+DOWNLOADED: screenshot @ 2024-04-24 06:42:22
[[file:12._Event_Storming/2024-04-24_06-42-22_screenshot.png]]

*** Read Models
   * A view of the data within the domain that the actor uses to make
     a decision to execute a command
   * e.g. a view of the data, a report, a notification, and so on
   * represented by green sticky notes


#+DOWNLOADED: screenshot @ 2024-04-24 06:45:41
[[file:12._Event_Storming/2024-04-24_06-45-41_screenshot.png]]

*** External Systems
   * represented by pink sticky notes


#+DOWNLOADED: screenshot @ 2024-04-24 06:46:32
[[file:12._Event_Storming/2024-04-24_06-46-32_screenshot.png]]

*** Aggregates
   * An aggregate receives commands and produces events
   * large yellow sticky notes, with commands on the left and events
     on the right


#+DOWNLOADED: screenshot @ 2024-04-24 06:47:41
[[file:12._Event_Storming/2024-04-24_06-47-41_screenshot.png]]

*** Bounded Contexts
   * Look for aggregates that are related to each other, either
     because they represent closely related functionality or because
     they're coupled through policies.
   * The groups of aggregates form natural candidates for bounded
     contexts' boundaries


#+DOWNLOADED: screenshot @ 2024-04-24 06:48:56
[[file:12._Event_Storming/2024-04-24_06-48-56_screenshot.png]]

*** Variants

The Event Storming process provides guidance, not hard rules. The
author usually introduces it with steps 1 (chaotic exploration) - 4
(pivotal events).

At the end of a full event storming session, you will have a model
describing the business domain's events, commands, aggregates, and
even possible bounded contexts.

*** Facilitation Tips

+ Start with a quick overview of the process
+ Build a legend
+ Watch the dynamics to either move on to another step or call it a day
+ Try to involve everyone
+ For online sessions, the author suggests making the top bound 5
  instead of 10

* 13. Domain-Driven Design in the Real World

This chapter focuses on strategies for applying DDD tools and patterns
in the real world, including on brownfield projects and in
less-than-ideal environments.

** Strategic Analysis
*** Understand the Business Domain
- What is the organization's business domain?
- Who are its customers?
- What service, or value, does the organization provide to customers?
- What companies or products is the organization competing with?

  Identify core, generic, and supporting subdomains

** Explore the Current Design

Once we are familiar with the problem domain, we can investigate the
solution and its design decisions.

- Start with high-level components
- Evaluate the tactical design
  - for each high level component, check which business subdomains it
    contains and what technical design decisions were taken
  - Does the solution fit the complexity of the problem? Are there
    areas where more elaborate design patterns are needed? Are there
    subdomains where we can use off-the-shelf solutions?
  - Use the knowledge gained to chart the current designs context map,
    as though these components were bounded contexts. Identify and
    track the relationships between the components in terms of bounded
    context integration patterns
    - Analyze the resulting context map from a DDD perspective. Are
      there suboptimal strategic design decisions?
      - e.g. multiple teams working on same high level component,
        duplicate implementations, implementation of a core subdomain
        by an outsourced company, friction because of frequently
        failing integration, awkward models spreading from external
        services and legacy systems

** Modernization Strategy

Think big, start small.

Pay attention to problems that the context integration patterns can
address:

- customer-supplier relationships
- anticorruption layer
- open-host service
- separate ways

* 14. Microservices

A microservice is a service with a micro-public interface: a
micro-front door. Reducing a service's functionality limits its
reasons for change and makes the service more autonomous for
development, management, and scale.

Effective modules are deep: a simple public interface encapsulates
complex logic. Ineffective modules are shallow: a shallow module's
public interface encapsulates much less complexity than a deep module.


** DDD and Microservices' Boundaries

Both microservices and bounded contexts are physical
boundaries. Bounded contexts impose limits on the widest valid
boundaries.


#+DOWNLOADED: screenshot @ 2024-04-24 16:58:19
[[file:14._Microservices/2024-04-24_16-58-19_screenshot.png]]


** Aggregates

The aggregate boundary is the narrowest boundary possible.

* 15. Event-Driven Architecture

** Events

In an EDA system, the exchange of events is the key communication
mechanism for integrating the components and making them a system.

Events
- a message describing a change that has already happened
Commands
- a message describing an operation that has to be carried out

** Event-Driven Design Heuristics

Guiding principles when designing event-driven systems:

- The network is going to be slow
- Servers will fail at the most inconvenient moment
- Events will arrive out of order
- Events will be duplicated

In event driven architectures, the whole system depends on successful
delivery of the messages. We must ensure events are delivered
consistently, no matter what:

- Use the outbox pattern to publish messages reliably
- When publishing messages, ensure deduplication and the ability to
  reorder messages if needed
- Leverage the saga and process manager patterns when orchestrating
  cross-bounded context processes that require issuing compensating
  actions.


* 16. Data Mesh

So far we have focused on models that handle online transactional
processing (OLTP) data. Another type of data that this chapter focused
on is online analytical processing (OLAP) data.

*Fact Table*
- Facts represent business activities that have already happened
- Never deleted or modified, append-only

*Dimension Table*
- If a fact represents a business process or action, a dimension
  describes the fact.
- Dimensions are designed to describe the facts attributes and are
  referenced as a aforeign key from a fact table to a dimension table.

** Analytical Data Management Platforms

*** Data Warehouse

Extract data from all of the enterprise's operational systems,
transform the source data into an analytical model, and load the
resultant data into a data analysis-oriented database.


#+DOWNLOADED: screenshot @ 2024-04-25 06:42:29
[[file:16._Data_Mesh/2024-04-25_06-42-29_screenshot.png]]

or with data marts:


#+DOWNLOADED: screenshot @ 2024-04-25 06:44:38
[[file:16._Data_Mesh/2024-04-25_06-44-38_screenshot.png]]

*** Data Lake

#+DOWNLOADED: screenshot @ 2024-04-25 06:46:04
[[file:16._Data_Mesh/2024-04-25_06-46-04_screenshot.png]]

Data lakes are schema-less and there is no control over the quality of
the incoming data. As a result, it is easy for the data to become
chaotic at certain levels of scale. The joke is that a data lake
becomes a data swamp.

** Data Mesh

Data mesh architecture defines and protexts model and ownership
boundaries for analytical data. It is based on 4 core principles:

- decompose data around domains
  - Instead of building a monolithic analytical model, data mesh
    suggests using multiple analytical models and align them with the
    origin of the data.
  - Each bounded context owns its operational and analytical models.

#+DOWNLOADED: screenshot @ 2024-04-25 06:52:10
[[file:16._Data_Mesh/2024-04-25_06-52-10_screenshot.png]]

- data as a product
  - Analytical data should be treated the same as any public API
    - it should be easy to discover the necessary endpoints: the data
      output ports
    - analytical endpoints should have a well-defined schema
      describing the served data and its format
    - data should be trustworthy with well defined and monitored
      service-level agreements (SLAs)
    - should be versioned as a regular API and manage
      integration-breaking changes in the model
- enable autonomy
  - product teams should be able to both create their own data
    products and consume data products served by other bounded
    contexts
- build an ecosystem
  - appoint a federated governance body to enable interoperability and
    ecosystem thinking.
  - the governance group is in change of defining the rules to ensure
    a healthy and interoperable ecosystem.


#+DOWNLOADED: screenshot @ 2024-04-25 06:58:41
[[file:16._Data_Mesh/2024-04-25_06-58-41_screenshot.png]]

* 17. Closing Words


#+DOWNLOADED: screenshot @ 2024-04-25 07:05:00
[[file:17._Closing_Words/2024-04-25_07-05-00_screenshot.png]]

* Appendix A: Applying DDD: A Case Study
